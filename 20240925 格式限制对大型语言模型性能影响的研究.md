### 摘要
结构化生成是以 JSON 和 XML 等标准化格式生成内容的过程，在实际应用中被广泛用于从大型语言模型LLMs）中提取关键输出信息。 本研究探讨了这种对生成空间的限制是否会影响LLMs的能力，包括推理和领域知识理解能力。 具体来说，我们评估了LLMs在各种常见任务中被限制遵守结构化格式和生成自由格式响应时的表现。 令人惊讶的是，我们发现在格式限制下，LLMs推理能力明显下降。 此外，我们还发现，在推理任务中，更严格的格式限制通常会导致更严重的性能下降。我们的代码和结果可在线查阅。

### 引言
Brown et al.(2020)和Wei 等人(2021)的指令跟随能力使大型语言模型（LLMs）能够解决下游任务。(2021)的大型语言模型LLMs）功能使其能够解决下游任务。然而，将LLMs纳入工业应用的一个主要障碍是它们不遵守标准化的输出格式。这种不一致性使输出解析复杂化，并削弱了这些模型的可靠性。

克服这一障碍的一种常见方法是结构化生成，即通过格式限制以 JSON 或 XML 等标准化格式提供输出。这些限制可以通过多种方式实现，例如通过格式限制指令指示LLMs遵循指定格式，或使用 JSON 模式OpenAI（2024 年）、Gemini（2024 年）、Instructor Liu（ 2024 年）或 GuardrailsPrefectHQ （ 2024 年 ）等工业解决方案。这些策略简化了解析工作流程，简化了将LLMs集成到实际应用中的过程。

由于对结构化生成的需求日益增长，研究界对调查LLMs的格式遵循能力表现出越来越大的兴趣。例如，IFEvalZhou et al.(2023), INFOBENCHQin et al.(2024)和 FOFOXia 等人 (2024) (2024)重点评估了LLMs的指令遵循能力，包括格式遵循能力。然而，这些研究并没有解决工业应用中的一个关键问题：限制格式的指令是否会影响LLMs 生成内容的质量？换句话说，这些研究没有探讨格式限制是否会降低LLMs的性能，而这将对业务产生重大影响。这种性能下降如图1 所示。

在这项工作中，我们通过大量的实证实验来解决上述研究问题。我们全面分析了格式限制指令对各种任务中LLMs性能的潜在影响。研究的格式包括 JSON、XML 和 YAML 等常用模式。据我们所知，这是首次对格式限制指令与生成内容质量之间的关系进行系统研究。我们的贡献有两个方面：
- 我们发现，在格式限制下LLMs的推理能力会下降，更严格的限制通常会导致推理任务的性能下降更多。
- 我们深入探讨了格式限制导致性能下降的原因，并提出了缓解这些问题的简单方法，从而实现一致的格式和最佳的性能。

### 结构化生成方法
为了研究不同程度的格式限制对下游性能的影响，我们在实验中采用了以下三种常用方法：
约束解码（JSON 模式）：约束解码是一种通过在生成过程中强制执行预定义标记空间来限制LLMs输出的技术。在主流LLM提供商中，JSON 模式是这种技术的一个广泛实施实例，特别是由于它在工业环境中的广泛应用。该模式可作为 OpenAI 和 Gemini API 中的超参数标志，确保输出为有效的 JSON。我们假定其实现类似于（Willard 和 Louf，2023 年；Koo 等人，2024 年）所描述的约束解码方法，并在文本生成推理2 中提供。
格式限制指令（FRI）：它们指示LLM按照指定的模式，以 JSON、XML 和 YAML 等标准化格式生成响应。这些指令确保生成的输出遵循结构化格式，便于提取和评估最终答案。这种方法比约束解码更为宽松，因为它不强制执行预定义的标记空间。
自然语言到格式：这一过程分为两步，首先指示LLM用自然语言回答问题，然后指示LLM将其回答转换为目标格式模式。作为结构化生成的最宽松版本，这种方法将内容生成与格式遵从分离开来，目的是在提供结构化输出的同时，保持无限制自然语言回答的性能。


### 数据集
我们采用了来自不同领域的数据集，并按其评估的主要技能进行了分类：
- 推理任务
- 分类任务

### 模式
在所有实验中，我们比较了 gpt-3.5-turbo-0125 OpenAI ( 2023)、laude-3-haiku-20240307（Team，2024a）、gemini-1.5-flash（Team 等人，2023）。对于开放权重模型，我们使用 LLaMA-3-8B-Instruct （Team, 2024b）和 Gemma-2-9B-Instruct （Team et al.

### 主要成果
我们通过考察三种逐步放宽的提示方法，研究了格式限制对LLM性能的影响：JSON 模式、FRI 和 NL 到格式转换。

我们在具有精确匹配分数的数据集上对这些方法进行了评估：图2 显示了 GSM8K 和 Last Letter Concatenation。令人惊讶的是，JSON 模式在 Last Letter 任务中的表现明显不如 FRI (JSON)。经过检查，我们发现 100％ 的 GPT 3.5 Turbo JSON 模式回答都将 "答案 "键放在了 "原因 "键之前，导致零次直接回答而不是零次思维链推理。

将 "NL-to-Format "与不受限制的 "自然语言 "应答进行比较，我们发现大多数模型的性能几乎相同，因为两者都是从相同的初始自然语言应答中得出答案的。不过，NL-to-Format 有时会引入生成错误，导致 LLaMA 3 8B Instruct 的性能略低，而其他模型在两种设置下的得分保持一致。

这些研究结果表明，格式限制的程度和实施会极大地影响LLM的性能，尤其是在推理任务中。结构化输出中按键的顺序以及推理与格式的脱钩是在提供结构化回复时保持LLM能力的重要因素。

在评估分类数据集时，我们观察到与推理任务不同的趋势，如图3 所示。值得注意的是，在 DDXPlus 数据集中，启用 JSON 模式后，Gemini 1.5 Flash 的性能大幅提升。在其他分类数据集中，JSON 模式的性能也很有竞争力，在某些情况下甚至超过了其他三种方法。

我们假设 JSON 模式通过限制可能的答案来提高分类任务的性能，从而减少答案选择中的错误。相反，自然语言回答可能会引入干扰，导致解析错误。这些发现表明，格式限制对LLM性能的影响取决于任务：严格的格式可能会妨碍推理密集型任务，但会提高需要结构化输出的分类任务的准确性。

